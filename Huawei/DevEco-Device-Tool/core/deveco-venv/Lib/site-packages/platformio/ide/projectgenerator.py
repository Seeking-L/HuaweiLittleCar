# Copyright (c) 2014-present PlatformIO <contact@platformio.org>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import codecs
import os
import sys
from os.path import basename, isdir, isfile, join, realpath, relpath
import json
import re
import shutil
import bottle
from platformio import fs, util
from platformio.proc import where_is_program
from platformio.project.config import ProjectConfig
from platformio.project.helpers import load_project_ide_data


class ProjectGenerator(object):
    def __init__(self, project_dir, ide, boards):
        self.config = ProjectConfig.get_instance(join(project_dir, ".deveco", "deveco.ini"))
        self.config.validate()
        self.project_dir = project_dir
        self.ide = str(ide)
        self.env_name = str(self.get_best_envname(boards))

    @staticmethod
    def get_supported_ides():
        tpls_dir = join(fs.get_source_dir(), "ide", "tpls")
        return sorted([d for d in os.listdir(tpls_dir) if isdir(join(tpls_dir, d))])

    def get_best_envname(self, boards=None):
        envname = None
        default_envs = self.config.default_envs()
        if default_envs:
            envname = default_envs[0]
            if not boards:
                return envname

        for env in self.config.envs():
            if not boards:
                return env
            if not envname:
                envname = env
            items = self.config.items(env=env, as_dict=True)
            if "board" in items and items.get("board") in boards:
                return env

        return envname

    @staticmethod
    def filter_includes(includes_map, ignore_scopes=None, to_unix_path=True):
        ignore_scopes = ignore_scopes or []
        result = []
        for scope, includes in includes_map.items():
            if scope in ignore_scopes:
                continue
            for include in includes:
                if to_unix_path:
                    include = fs.to_unix_path(include)
                if include not in result:
                    result.append(include)
        return result

    def _load_tplvars(self):
        tpl_vars = {
            "config": self.config,
            "systype": util.get_systype(),
            "project_name": basename(self.project_dir),
            "project_dir": self.project_dir,
            "env_name": self.env_name,
            "user_home_dir": realpath(fs.expanduser("~")),
            "platformio_path": sys.argv[0]
            if isfile(sys.argv[0])
            else where_is_program("hos"),
            "env_path": os.getenv("PATH"),
            "env_pathsep": os.pathsep,
            "environments": {}
        }

        # default env configuration
        tpl_vars.update(self.config.items(env=self.env_name, as_dict=True))
        tpl_vars.update(load_project_ide_data(self.project_dir, self.env_name) or {})
        # env configuration
        for env in self.config.envs():
            tpl_vars['environments'][env] = {}
            tpl_vars['environments'][env].update(self.config.items(env=env, as_dict=True))
            tpl_vars['environments'][env].update(load_project_ide_data(self.project_dir, env) or {})

        with fs.cd(self.project_dir):
            tpl_vars.update(
                {
                    "src_files": self.get_src_files(),
                    "project_src_dir": self.config.get_optional_dir("src"),
                    "project_lib_dir": self.config.get_optional_dir("lib"),
                    "project_libdeps_dir": join(self.config.get_optional_dir("libdeps"), self.env_name),
                }
            )

        for key, value in tpl_vars.items():
            if key.endswith(("_path", "_dir")) and not key.startswith("is"):
                tpl_vars[key] = fs.to_unix_path(value)
        for key in ("src_files", "libsource_dirs"):
            if key not in tpl_vars:
                continue
            tpl_vars[key] = [fs.to_unix_path(inc) for inc in tpl_vars[key]]

        tpl_vars["to_unix_path"] = fs.to_unix_path
        tpl_vars["filter_includes"] = self.filter_includes
        return tpl_vars

    def get_src_files(self):
        result = []
        with fs.cd(self.project_dir):
            for root, _, files in os.walk(self.config.get_optional_dir("src")):
                for f in files:
                    result.append(relpath(join(root, f)))
        return result

    def get_tpls(self):
        tpls = []
        tpls_dir = join(fs.get_source_dir(), "ide", "tpls", self.ide)
        for root, _, files in os.walk(tpls_dir):
            for f in files:
                if not f.endswith(".tpl"):
                    continue
                _relpath = root.replace(tpls_dir, "")
                if _relpath.startswith(os.sep):
                    _relpath = _relpath[1:]
                tpls.append((_relpath, join(root, f)))
        return tpls

    def generate(self):
        tpl_vars = self._load_tplvars()
        for tpl_relpath, tpl_path in self.get_tpls():  # pylint: disable=unused-variable
            dst_dir = self.project_dir
            if tpl_relpath:
                dst_dir = join(self.project_dir, tpl_relpath)
                if not isdir(dst_dir):
                    os.makedirs(dst_dir)
            file_name = basename(tpl_path)[:-4]
            contents = self._render_tpl(tpl_path, tpl_vars)
            self._merge_contents(join(dst_dir, file_name), contents)

    @staticmethod
    def _render_tpl(tpl_path, tpl_vars):
        with codecs.open(tpl_path, "r", encoding="utf8") as fp:
            return bottle.template(fp.read(), **tpl_vars)

    @staticmethod
    def _merge_contents(dst_path, contents):  # pylint: disable=too-many-statements

        def append_uniq(targetlist):
            if not isinstance(targetlist, list):
                raise TypeError(f"{targetlist} not a list")
            res = []
            for elem in targetlist:
                if elem not in res:
                    res.append(elem)
            return res

        def merge(user, template, extend_arrays=None, compare_key=None):
            for k in template.keys():  # process only 1st level of merging dictionaries
                if not extend_arrays or not isinstance(template[k], list):  # it's simple replace
                    user[k] = template[k]
                else:  # it's array element and need to extend it
                    _merge_handle(k, user, template, extend_arrays, compare_key)
            return user

        def _merge_handle(k, user, template, extend_arrays, compare_key):
            if k not in user or not isinstance(user[k], list):
                # destination is not array - it's wrong, just replace it
                user[k] = template[k]
            else:
                if k == extend_arrays and not compare_key:
                    # it's array of simple elements - just extend and remove duplicates
                    user[k].extend(template[k])
                    user[k] = append_uniq(user[k])
                elif k == extend_arrays:
                    # it's array of dictionaries, use compare_key to make a dictionary with unique items
                    uniq_user = {v[compare_key]: v for v in user[k] if compare_key in v}
                    uniq_templ = {v[compare_key]: v for v in template[k] if compare_key in v}
                    user[k] = list(merge(uniq_user, uniq_templ).values())  # now, just simple merge them
                else:
                    user[k] = template[k]

        def _json_dumps_with_indent(configs):
            indent = ' ' * 8
            postfix = ',' + os.linesep
            return postfix.join(
                os.linesep.join(indent + line for line in json.dumps(o, indent=4).splitlines()) for o in configs)

        def _save_launch(user_content, template_data, path):
            var = [
                '{',
                '    "version": "0.2.0",',
                '    "configurations": [',
                '        // Deveco auto-generated start',
                _json_dumps_with_indent(template_data)
            ]
            if user_content and template_data:
                var[-1] += ','
            var.append('        // Deveco auto-generated end')
            var.append(_json_dumps_with_indent(user_content))
            var.append('    ]')
            var.append('}')
            var.append('')

            codecs.open(path, 'w', encoding="utf8").write(os.linesep.join(var))

        def _get_user_launch(path):
            if os.path.isfile(path):
                # cut auto-generated content
                content = codecs.open(path, "r", encoding="utf8").read()
                start_pattern = r'//\sDeveco\sauto-generated\sstart'
                end_pattern = r'//\sDeveco\sauto-generated\send'
                content = re.sub(r'(?=' + start_pattern + r')(.*?)(?<=' + end_pattern + r')', '', content, flags=re.S)
                if re.findall(start_pattern + r'|' + end_pattern, content):
                    content = ''  # something wrong with auto-generated sections, set invalid content
                # parse data
                try:
                    return json.loads(content)
                except Exception:  # pylint: disable=broad-except
                    shutil.copyfile(path, path + '.back')  # source file is wrong: keep origin content to back file
            return {"configurations": []}

        def _set_merge_file_data(path, templatedata, merge_files, name):
            if isfile(path):
                with codecs.open(path, "r", encoding="utf8") as fp:
                    userdata = json.loads(fp.read())
                savedata = userdata
            else:
                savedata = templatedata
            with codecs.open(path, "w", encoding="utf8") as fp:
                if savedata == {}:
                    fp.write('{' + os.linesep + '}')
                else:
                    json.dump(savedata, fp, indent=4)

        merge_files_params = {
            "settings.json": [None, None],
            "extensions.json": ["recommendations", None],
            "c_cpp_properties.json": ['configurations', 'name']
        }
        filename = basename(dst_path)
        if filename == ".gitignore" and isfile(dst_path):
            return
        if filename == "tasks.json":
            return
        # check that file need to be merged
        try:
            if filename in merge_files_params:
                templatedata = json.loads(contents)
                _set_merge_file_data(dst_path, templatedata, merge_files_params, filename)
            elif filename == 'launch.json':
                userdata = _get_user_launch(dst_path)
                templatedata = json.loads(contents)
                userconf = userdata.get('configurations', [])
                for uc in userconf:
                    templatedata['configurations'] = [x for x in templatedata['configurations'] if
                                                      x['name'] != uc.get('name', '')]
                _save_launch(userconf, templatedata['configurations'], dst_path)

            else:
                with codecs.open(dst_path, "w", encoding="utf8") as fp:
                    fp.write(contents)
        except Exception as e:
            raise Exception('merge contents failed!') from e
