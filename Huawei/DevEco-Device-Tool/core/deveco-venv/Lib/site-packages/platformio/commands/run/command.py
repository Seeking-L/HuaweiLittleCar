# Copyright (c) 2014-present PlatformIO <contact@platformio.org>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import json
from multiprocessing import cpu_count
import os
from os import environ
from os import getcwd
from os.path import isfile, join
from time import time
import re
import collections
import click
from tabulate import tabulate

from string import Template
from platformio import app, exception, fs, util
from platformio.commands.device.command import device_monitor as cmd_device_monitor
from platformio.commands.run.helpers import clean_build_dir, handle_legacy_libdeps, update_partition_config
from platformio.commands.run.processor import EnvironmentProcessor
from platformio.commands.test.processor import CTX_META_TEST_IS_RUNNING
from platformio.project.config import ProjectConfig
from platformio.project.helpers import find_project_dir_above
from platformio.rpc.helpers import execute_remote_command
from platformio.commands.dotting.helpers import TraceOperate, TaskTrace
from platformio.helpers import get_suite_json_path
from platformio.commands.run.helpers import run_exec, get_burn_json_path, read_json_file
from platformio.proc import split_cmd_line, quote_cmd_line
from platformio.commands.exception import UnknownError

# pylint: disable=too-many-arguments,too-many-locals,too-many-branches,too-many-statements

try:
    DEFAULT_JOB_NUMS = cpu_count()
except NotImplementedError:
    DEFAULT_JOB_NUMS = 1

RunCliArgs = collections.namedtuple('RunCliArgs', [
    'ctx',
    'environment',
    'target',
    'partition',
    'upload_port',
    'project_dir',
    'project_conf',
    'jobs',
    'silent',
    'client_port',
    'verbose',
    'disable_auto_clean',
    'custom_tool_path',
    'force_local',
    'burn_json_path',
    'tool_path'])


@click.command("run", short_help="Process project environments")
@click.option("-e", "--environment", multiple=True)
@click.option("-t", "--target", multiple=True)
@click.option("-p", "--partition", multiple=True)
@click.option("--upload-port")
@click.option("-d", "--project-dir", default=getcwd,
              type=click.Path(exists=True, file_okay=True, dir_okay=True, writable=True, resolve_path=True))
@click.option("-c", "--project-conf",
              type=click.Path(exists=True, file_okay=True, dir_okay=False, readable=True, resolve_path=True))
@click.option("-j", "--jobs", type=int, default=DEFAULT_JOB_NUMS,
              help="Allow N jobs at once. Default is a number of CPUs in a system (N=%d)" % DEFAULT_JOB_NUMS)
@click.option("-s", "--silent", is_flag=True)
@click.option("--client-port", required=False)
@click.option("-v", "--verbose", is_flag=True)
@click.option("--disable-auto-clean", is_flag=True)
@click.option("--custom-tool-path", default='')
@click.option("--burn-json-path", default='')
@click.option("--tool-path", default='')
@click.option("--force-local", is_flag=True, default=None)
@click.pass_context
def cli(ctx, environment, target, partition, upload_port, **kwargs):
    project_dir = kwargs.get("project_dir")
    project_conf = kwargs.get("project_conf")
    jobs = kwargs.get("jobs")
    silent = kwargs.get("silent")
    client_port = kwargs.get("client_port")
    verbose = kwargs.get("verbose")
    disable_auto_clean = kwargs.get("disable_auto_clean")
    custom_tool_path = kwargs.get("custom_tool_path")
    force_local = kwargs.get("force_local")
    app.set_session_var("custom_project_conf", project_conf)

    burn_json_path = kwargs.get("burn_json_path", '')
    tool_path = kwargs.get("tool_path", '')

    # set force_local if remote port env variable is not set. If force_local is set explicitly then use its value
    force_local = not environ.get('DEVECO_REMOTE_SERVER_PORT', False) if force_local is None else force_local

    # find project directory on upper level
    if isfile(project_dir):
        project_dir = find_project_dir_above(project_dir)

    is_test_running = CTX_META_TEST_IS_RUNNING in ctx.meta

    with fs.cd(project_dir):
        config = ProjectConfig.get_instance(project_conf)
        config.validate(environment)
        clean_obsolete_build_dir(disable_auto_clean, config)
        handle_legacy_libdeps(project_dir, config)

        default_envs = config.default_envs()
        results = []

        if not target:
            target = ['buildprog']

        for env in config.envs():
            skipenv = any(
                [
                    environment and env not in environment,
                    not environment and default_envs and env not in default_envs,
                ]
            )
            if skipenv:
                for t in target:
                    results.append({"env": env, "target": t})
                continue

            # print empty line between multi environment project
            if not silent and any(r.get("succeeded") is not None for r in results):
                click.echo()

            export_vars = get_export_vars(partition, upload_port, config, env)

            always_local_targets = ['clean', 'buildprog', 'idedata', "debug", "sizedata", "envdump",
                                    "run", "stackAnalysis", "imageAnalysis", "perfAnalysis",
                                    "build_ota", "menuconfig", "patch_kernel", "make"]

            env_target_info = dict(always_local_targets=always_local_targets, env=env, config=config,
                                   target=target, export_vars=export_vars, is_test_running=is_test_running)
            run_cli_args = RunCliArgs(ctx, environment, target, partition, upload_port, project_dir,
                                      project_conf, jobs, silent, client_port, verbose, disable_auto_clean,
                                      custom_tool_path, force_local, burn_json_path, tool_path)

            process_targets(results, env_target_info, run_cli_args)

        process_command_results(results, config, is_test_running, silent, kwargs.get("force_local"))
        return True


def process_targets(results, env_target_info, run_cli_args):
    always_local_targets = env_target_info.get('always_local_targets')
    env = env_target_info.get('env')
    config = env_target_info.get('config')
    target = env_target_info.get('target')
    export_vars = env_target_info.get('export_vars')
    is_test_running = env_target_info.get('is_test_running')

    ctx = run_cli_args.ctx
    environment = run_cli_args.environment
    target = run_cli_args.target
    partition = run_cli_args.partition
    project_dir = run_cli_args.project_dir
    jobs = run_cli_args.jobs
    silent = run_cli_args.silent
    client_port = run_cli_args.client_port
    verbose = run_cli_args.verbose
    custom_tool_path = run_cli_args.custom_tool_path
    force_local = run_cli_args.force_local

    suite_burn_enable = config.get('env:' + env, 'suite_burn_enable')

    for t in target:
        if suite_burn_enable and t in ['upload']:
            r = process_suite_upload(env, env_target_info, force_local, t, run_cli_args)
        elif force_local or t in always_local_targets:
            r = process_env(ctx, env, config, environment,
                            targets=[t], export_vars=export_vars, silent=silent, client_port=client_port,
                            verbose=verbose, jobs=jobs, is_test_running=is_test_running, list_files=False,
                            custom_tool_path=custom_tool_path)
            r["target"] = t
        else:
            is_remote = True
            process_upload_partitions(t, config, env, partition, project_dir)

            collected = process_env(ctx, env, config, environment, targets=[t], export_vars=export_vars, silent=silent,
                                    client_port=client_port, verbose=verbose, jobs=jobs,
                                    is_test_running=is_test_running, list_files=True, custom_tool_path=custom_tool_path)
            files = json.loads(collected["succeeded"]["out"])[t]
            files.append(join(".deveco", "deveco.ini"))
            command = generate_command(env, t, run_cli_args)
            env_info = dict(target=t, env=env, config=config,
                            project_dir=project_dir, environment=environment, command=command)
            download_tools = handle_upload_tools(env_info)
            dot_remote_files(files, t, env, config, run_cli_args)

            r = {"env": env,
                 "target": t,
                 "startTime": time(),
                 "succeeded": execute_remote_command(command=command, project_dir=project_dir,
                                                     files=files, upload_tools=download_tools)}
            r["endTime"] = time()
            r["duration"] = r["endTime"] - r["startTime"]
            r['is_remote'] = is_remote
        results.append(r)


def process_suite_local_upload(env, config, burn_json_path, tool_path, target):
    if not os.path.exists(burn_json_path):
        click.secho('Please config burn json path', fg="yellow")
        raise exception.ReturnErrorCode(1)

    if not os.path.exists(tool_path):
        click.secho('Please config tool path', fg="yellow")
        raise exception.ReturnErrorCode(1)

    try:
        command_list = get_upload_command(burn_json_path, env, config, tool_path)
    except (ValueError, AttributeError):
        click.secho('The data format of the adaptation file is incorrect.', fg="yellow")
        raise exception.ReturnErrorCode(1)

    results = {"env": env, "startTime": time()}
    result = -1
    for command in command_list:
        command = split_cmd_line(command)
        result = run_exec(command)
        if result != 0:
            break

    results["succeeded"] = result == 0
    results["endTime"] = time()
    results["duration"] = results["endTime"] - results["startTime"]
    results["target"] = target

    return results


def process_suite_remote_upload(env, config, run_cli_args, target):
    project_dir = run_cli_args.project_dir
    is_remote = True

    framework = config.get('env', 'framework', [])
    product = config.get('env:' + env, 'board_frameworks.hb.build.product', '') \
        if 'hpm' not in framework else config.get("env:" + env, 'hpm_project_base_package', '')

    if not config.has_section('burn:' + product):
        click.secho('Please load burn json', fg="yellow")
        raise exception.ReturnErrorCode(1)

    upload_task = config.get('burn:' + product, 'upload_task', '')
    if not upload_task:
        click.secho('Upload_task not in adapter config file or please config upload_task', fg="yellow")
        raise exception.ReturnErrorCode(1)

    json_path, tool_path = get_burn_json_path(config, env, project_dir)

    suite_json_path = get_suite_json_path(project_dir, product)
    info = read_json_file(suite_json_path)

    files = []

    partitions_config = info.get('partitions_config', {})
    for k, v in partitions_config.items():
        if 'dependent' in v and upload_task not in v['dependent']:
            continue
        bin_file = config.get('burn:' + product, k, '') 
        if bin_file and os.path.exists(bin_file):
            files.append(bin_file)
        else:
            msg = f'{bin_file} is not exists' if bin_file else f'Please config {k}'
            click.secho(msg, fg="yellow")
            raise exception.ReturnErrorCode(1)

    files.append(join(".deveco", "deveco.ini"))

    command = generate_command(env, target, run_cli_args)

    command.extend(['--burn-json-path', json_path])
    command.extend(['--tool-path', tool_path])

    results = {"env": env,
            "target": target,
            "startTime": time(),
            "succeeded": execute_remote_command(command=command, project_dir=project_dir,
                                                files=files)}
    results["endTime"] = time()
    results["duration"] = results["endTime"] - results["startTime"]
    results['is_remote'] = is_remote

    return results


def process_suite_upload(env, env_target_info, force_local, target, run_cli_args):
    config = env_target_info.get('config')
    burn_json_path = run_cli_args.burn_json_path
    tool_path = run_cli_args.tool_path

    if force_local:
        results = process_suite_local_upload(env, config, burn_json_path, tool_path, target)
    else:
        results = process_suite_remote_upload(env, config, run_cli_args, target)

    # print footer on error or when is not unit testing
    is_test_running = env_target_info.get('is_test_running')
    silent = run_cli_args.silent
    is_print_footer = all([
        not is_test_running,
        not silent or not results["succeeded"],
        not force_local
    ])
    if is_print_footer:
        print_processing_footer(results)

    return results


def get_upload_command(burn_json_path, env, config, tool_path):
    framework = config.get('env', 'framework', [])
    product = config.get('env:' + env, 'board_frameworks.hb.build.product', '') \
        if 'hpm' not in framework else config.get("env:" + env, 'hpm_project_base_package', '')

    if not config.has_section('burn:' + product):
        click.secho('Please load burn json', fg="yellow")
        raise exception.ReturnErrorCode(1)

    burn_partition = f'burn:{product}' 

    upload_task = config.get(burn_partition, 'upload_task', '')
    if not upload_task:
        click.secho('Upload_task not in adapter config file or please config upload_task', fg="yellow")
        raise exception.ReturnErrorCode(1)

    info = read_json_file(burn_json_path)

    arg_command = dict(tool_path=quote_cmd_line(tool_path))

    config_data = info.get('partitions_config', {})
    config_data.update(info.get('ui_config', {}))
    config_arg = dict(upload_task=upload_task, burn_partition=burn_partition)
    set_arg_command(config_data, config, config_arg, arg_command)

    commands = info.get('commands', {})
    command_list = get_task_command_list(upload_task, commands, tool_path, arg_command)

    # get expansion
    expansion = commands.get('expansion', {})
    for k, v in expansion.items():
        if 'dependent' in v and upload_task not in v['dependent']:
            continue
        ui_arg = config.get(burn_partition, k, '')
        if ui_arg:
            command_index = v.get('command_index', -1)
            if command_index < len(command_list):
                arg_command[k] = quote_cmd_line(ui_arg)
                command_list[command_index] += ' ' + v.get('command', '')
            else:
                click.secho(f'command index out of range:{command_index}.', fg="yellow")
                raise exception.ReturnErrorCode(1)

    command_list = [Template(command).safe_substitute(arg_command) for command in command_list]

    return command_list


def set_arg_command(config_data, config, config_arg, arg_command):
    upload_task = config_arg.get('upload_task')
    burn_partition = config_arg.get('burn_partition')
    for k, v in config_data.items():
        if 'dependent' in v and upload_task not in v['dependent']:
            continue

        ui_arg = config.get(burn_partition, k, '')
        if ui_arg:
            if k == 'upload_port' and 'convert' in v and v['convert']:
                ui_arg = convert_upload_port(ui_arg)

            path_list = ['file', 'directory']
            if 'type' in v and v['type'] in path_list and not os.path.exists(ui_arg):
                click.secho(f'{ui_arg} is not exists', fg="yellow")
                raise exception.ReturnErrorCode(1)

            arg_command[k] = quote_cmd_line(ui_arg)
        else:
            click.secho(f'Please config {k}', fg="yellow")
            raise exception.ReturnErrorCode(1)


def convert_upload_port(port):
    re_res = re.match(r'com(\d+)', port, re.I)
    if re_res:
        port = re_res.group(1)
    return port


def get_task_command_list(upload_task, commands, tool_path, arg_command):
    tool_command = commands.get('tool_command', {})

    dependent_tool = tool_command.get('dependent_tool', {})
    for k, v in dependent_tool.items():
        if '${tool_dir}' in v:
            tool_dir = os.path.abspath(os.path.join(tool_path, ".."))
            v = Template(v).safe_substitute(tool_dir=tool_dir)
        arg_command[k] = quote_cmd_line(v)

    command = tool_command.get('command', '')

    task_command = commands.get('task', {}).get(upload_task, {}).get('command')
    if not task_command:
        click.secho(f'{upload_task} command not find', fg="yellow")
        raise exception.ReturnErrorCode(1)

    command_list = []
    if isinstance(task_command, list):
        for task in task_command:
            command_list.append(command + ' ' + task)
    elif isinstance(task_command, str):
        command_list.append(command + ' ' + task_command)
    else:
        click.secho(f'{upload_task} command type is not supported.', fg="yellow")
        raise exception.ReturnErrorCode(1)

    return command_list


def generate_command(env, target, run_cli_args):
    command = ['hos', 'run',
               '--environment', env,
               '--target', target,
               '--project-dir', run_cli_args.project_dir,
               '--jobs', str(run_cli_args.jobs),
               '--force-local']

    for p in run_cli_args.partition:
        command.extend(['--partition', p])
    if run_cli_args.upload_port:
        command.extend(['--upload-port', run_cli_args.upload_port])
    if run_cli_args.client_port:
        command.extend(['--client-port', run_cli_args.client_port])
    if run_cli_args.project_conf:
        command.extend(['--project-conf', run_cli_args.project_conf])
    if run_cli_args.silent:
        command.append('--silent')
    if run_cli_args.verbose:
        command.append('--verbose')
    if run_cli_args.disable_auto_clean:
        command.append('--disable-auto-clean')
    return command


def get_upload_tools(env, config, project_dir):
    tool_status = {}
    tools = {}
    ohos_version = config.get('env', 'ohos_version', '')
    framework = config.get('env', 'framework', [])
    product = config.get('env:' + env, 'board_frameworks.hb.build.product', '') \
        if 'hpm' not in framework else config.get("env:" + env, 'hpm_project_base_package', '')
    if ohos_version and product:
        cache_status_path = join(project_dir, '.deveco', 'status', f'{re.sub("[@/]", ".", product)}')
        if isfile(cache_status_path):
            tool_status = json.load(open(cache_status_path, 'r'))

    if tool_status:
        tools = tool_status.get('tools', {}).get('upload', {})

    return tools


def upload_check(upload_tools, env_info, download_tools):
    target = env_info.get('target')
    env = env_info.get('env')
    config = env_info.get('config')
    environment = env_info.get('environment')
    command = env_info.get('command')
    for k, v in upload_tools.items():
        if not v.get('valid', False):
            fail_cause = f"In the `{environment}` environment, the `{target}` task fails " \
                         f"because the burning tool ({k}) does not valid."
            result = {"succeeded": False, 'fail_cause': fail_cause}
            TraceOperate(TaskTrace).operate('Task', target, env, config, result, True)
            click.secho(fail_cause, fg="yellow")
            raise exception.ReturnErrorCode(1)
        elif v.get('custom', ''):
            command.extend(['--custom-tool-path', v['dest']])
        else:
            download_tools[k] = v
            if not os.path.exists(os.path.join(v['store'], v['zip_name'])):
                fail_cause = f"In the `{environment}` environment, the `{target}` task fails " \
                             f"because the burning tool ({k}) does not exist."
                result = {"succeeded": False, 'fail_cause': fail_cause}
                TraceOperate(TaskTrace).operate('Task', target, env, config, result, True)
                click.secho(fail_cause, fg="yellow")
                raise exception.ReturnErrorCode(1)


def handle_upload_tools(env_info):
    target = env_info.get('target')
    env = env_info.get('env')
    config = env_info.get('config')
    project_dir = env_info.get('project_dir')
    download_tools = {}
    if target in ['upload', "erase"]:
        # In remote mode, dotting when the burning tool is missing
        upload_tools = get_upload_tools(env, config, project_dir)
        upload_check(upload_tools, env_info, download_tools)
    return download_tools


def get_export_vars(partition, upload_port, config, env):
    export_vars = []
    if partition:
        config.set("env:" + env, "upload_partitions", partition)
        export_vars.append("upload_partitions")
    if upload_port:
        config.set("env:" + env, "upload_port", upload_port)
        export_vars.append("upload_port")
    return export_vars


def clean_obsolete_build_dir(disable_auto_clean, config):
    if not disable_auto_clean:
        build_dir = config.get_optional_dir("build")
        try:
            clean_build_dir(build_dir, config)
        except Exception as e:  # pylint: disable=bare-except
            UnknownError(e)


def process_upload_partitions(target, config, env, partition, project_dir):
    use_profile = config.get('env:' + env, 'use_partitions_profile', False)
    if target in ['upload', "erase"] and not partition and use_profile:
        profile = config.get('env:' + env, 'upload_partitions_profile', '')
        if profile:
            env_platform = config.get('env:' + env, 'platform', '')
            update_partition_config(env, env_platform, project_dir, profile)
        else:
            click.secho('The upload partitions profile is empty, Please configure  \
            upload_partitions_profile', fg="yellow")
            raise exception.ReturnErrorCode(1)


def dot_remote_files(files, target, env, config, run_cli_args):
    # In remote mode, dotting when the burning file is missing
    for f in files:
        if not os.path.exists(os.path.join(run_cli_args.project_dir, f)):
            fail_cause = f"In the `{run_cli_args.environment}` environment, the `{target}` task fails " \
                         f"because the burning file ({f}) does not exist."
            result = {"succeeded": False, 'fail_cause': fail_cause}
            TraceOperate(TaskTrace).operate('Task', target, env, config, result, True)
            click.secho(fail_cause, fg="yellow")
            raise exception.ReturnErrorCode(1)


def process_command_results(results, config, is_test_running, silent, force_local):
    command_failed = any(r.get("succeeded") is False for r in results)
    is_print_summary = all([
        not is_test_running,
        command_failed or not silent,
        len(results) > 1,
        not force_local
    ])
    for r in results:
        TraceOperate(TaskTrace).operate('Task', r.get('target'), r.get('env'), config, r, r.get('is_remote', False))
    if is_print_summary:
        print_processing_summary(results)

    if command_failed:
        raise exception.ReturnErrorCode(1)


def process_env(ctx, name, config, environments, **kwargs):
    targets = kwargs.get("targets")
    export_vars = kwargs.get("export_vars")
    silent = kwargs.get("silent")
    client_port = kwargs.get("client_port")
    verbose = kwargs.get("verbose")
    jobs = kwargs.get("jobs")
    is_test_running = kwargs.get("is_test_running")
    list_files = kwargs.get("list_files")
    custom_tool_path = kwargs.get("custom_tool_path")

    if not is_test_running and not silent and not list_files:
        print_processing_header(name, config, verbose)

    ep = EnvironmentProcessor(
        ctx, name, config, targets, export_vars, silent, client_port, verbose, jobs, list_files, custom_tool_path
    )
    result = {"env": name, "startTime": time(), "succeeded": ep.process()}
    result["endTime"] = time()
    result["duration"] = result["endTime"] - result["startTime"]

    # print footer on error or when is not unit testing
    is_print_footer = all([
        not is_test_running,
        not silent or not result["succeeded"],
        not list_files
    ])
    if is_print_footer:
        print_processing_footer(result)

    if (
            result["succeeded"]
            and "monitor" in ep.get_build_targets()
            and "nobuild" not in ep.get_build_targets()
    ):
        ctx.invoke(
            cmd_device_monitor, environment=environments[0] if environments else None
        )

    return result


def print_processing_header(env, config, verbose=False):
    env_dump = []
    for k, v in config.items(env=env):
        if verbose or k in ("platform", "framework", "board"):
            env_dump.append("%s: %s" % (k, ", ".join(v) if isinstance(v, list) else v))
    click.echo(
        "Processing %s (%s)"
        % (click.style(env, fg="cyan", bold=True), "; ".join(env_dump))
    )
    terminal_width, _ = click.get_terminal_size()
    click.secho("-" * terminal_width, bold=True)


def print_processing_footer(result):
    is_failed = not result.get("succeeded")
    util.print_labeled_bar(
        "[%s] Took %.2f seconds"
        % (
            (
                click.style("FAILED", fg="red", bold=True)
                if is_failed
                else click.style("SUCCESS", fg="green", bold=True)
            ),
            result["duration"],
        ),
    )


def print_processing_summary(results):
    tabular_data = []
    succeeded_nums = 0
    failed_nums = 0
    duration = 0

    for result in results:
        duration += result.get("duration", 0)
        if result.get("succeeded") is False:
            failed_nums += 1
            status_str = click.style("FAILED", fg="red")
        elif result.get("succeeded") is None:
            status_str = "IGNORED"
        else:
            succeeded_nums += 1
            status_str = click.style("SUCCESS", fg="green")

        tabular_data.append(
            (
                click.style(result["env"], fg="cyan"),
                result["target"],
                status_str,
                util.humanize_duration_time(result.get("duration")),
            )
        )

    click.echo()
    click.echo(
        tabulate(
            tabular_data,
            headers=[
                click.style(s, bold=True) for s in ("Environment", "Target", "Status", "Duration")
            ],
        ),
        err=failed_nums,
    )

    util.print_labeled_bar(
        "%s%d succeeded in %s"
        % (
            "%d failed, " % failed_nums if failed_nums else "",
            succeeded_nums,
            util.humanize_duration_time(duration),
        ),
        is_error=failed_nums,
        fg="red" if failed_nums else "green",
    )
