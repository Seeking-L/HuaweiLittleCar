#!/user/bin/env python3
# coding=utf-8

import json
import math
import sqlite3
import time
from enum import Enum, auto

from liteos_optimize_adapter.business.trace.event_codes_config_parser import LOS_TRACE_TYPE
from liteos_optimize_adapter.business.trace.trace_database_service import TraceDatabaseService

CPU_INTERVAL = 0.1
MEM_INTERVAL = 0.1


class DataType(Enum):
    Timeline = 0
    TraceLiteEvent = auto()
    CpuUsage = auto()
    MemoryUsage = auto()
    TaskList = auto()
    CpuId = auto()
    MemPool = auto()


class TraceDataBaseWriter():

    def __init__(self, trace_header):
        self.trace_header = trace_header
        self.database_service = TraceDatabaseService()

        self.database_path = ''
        self.database = None
        self.database_cursor = None

        # TaskList
        self.task_datas = []
        self.task_name = {}
        self.task_type = 0

        # cpu usage
        self.cpup_start_time = {}
        self.cpup_count = 0
        self.cpup_tasks = {}
        self.cpu_id = []
        self.cpup_last_start_time = {}

        # heap info
        self.heap_start_time = 0
        self.mem_pool = {}

        self.sql_count = 0
        self.sql_data = []

        self.task_start_time = {}
        self.task_end_time = {}

        self.last_task = {}
        self.last_time_line_sql = {}

    def init(self, database_path):
        if database_path:
            self.database_path = database_path

    def close_database(self):
        if self.database is not None:
            try:
                self.database.close()
                self.database = None
            except Exception as e:
                print('close database failed')
                raise Exception() from e

    def insert_trace_event_data(self, custom_data, if_insert_data=True, is_finished=False):
        sqlInsert_timeline = 'insert into Timeline(timestamp, cpuid,datatype, itemstring) values(?,?,0,?)'
        sql_all = []
        for data in custom_data:
            timestamp_val = data.get('timestamp')
            if timestamp_val:
                # Record Task Name
                self.set_task_list_data(data, sql_all)
                self.set_event_cpu_data(data, sql_all)
                self.set_time_line_data(data, sql_all)
                self.set_cpu_usage_data(data, sql_all)
                self.set_task_state(data)
                self.set_heap_mem_data(data, sql_all)

        if is_finished == True:
            for cpuid in self.last_time_line_sql:
                if len(self.last_time_line_sql.get(cpuid)) > 0:
                    sql_all.append({
                        'sql': sqlInsert_timeline,
                        'data': self.last_time_line_sql.get(cpuid)
                    })

        if if_insert_data == True:
            self.insert_trace_data_to_database(sql_all)

        return sql_all

    def set_task_list_data(self, data, sql_all):
        sqlInsert_tasklist = 'insert into TaskList(timestamp, cpuid,datatype, itemstring) values(?,?,4,?)'
        cpuid_val = data.get('cpuid')
        actor_val = data.get('Actor')
        actor_addr_val = data.get('ActorAddr')
        timestamp_val = data.get('timestamp')
        is_exists = 0
        id_iter = {
            'id': 0,
            'type': 1,
            'taskname': 'undefined',
            'addr': '',
            'taskId': '',
            'state': ''
        }
        task_id = actor_addr_val[6: 10]
        task_index = -1
        for idx, item in enumerate(self.task_datas):
            if item.get('taskId') == task_id and item.get('taskname') == actor_val:
                if item.get('state') != 'delete':
                    is_exists = 1
                    data['ActorAddr'] = item.get('addr')
                    break
                if data['code'] == '0x' + str(hex(LOS_TRACE_TYPE.TRACE_EVENT_CREATE.value)):
                    task_index = idx
                else:
                    is_exists = 1
                    data['ActorAddr'] = item.get('addr')
                    break

        if task_index != -1:
            self.task_datas.pop(task_index)
        if is_exists == 0 and actor_val != 'Interrupt':
            id_iter['taskname'] = actor_val
            id_iter['addr'] = actor_addr_val
            id_iter['taskId'] = task_id
            id_iter['state'] = "new"
            self.task_datas.append(id_iter)
            sql_all.append({
                'sql': sqlInsert_tasklist,
                'data': [timestamp_val, cpuid_val, json.dumps(id_iter)]
            })

    def set_event_cpu_data(self, data, sql_all):
        sqlInsert = 'insert into TraceLiteEvent(timestamp, timestampOri,cpuid,datatype,' \
                    'eventCount,eventType,identity,itemstring) values(?,?,?,1,?,?,?,?)'
        sqlInsert_cpuid = 'insert into CpuId(timestamp, cpuid,datatype, itemstring) values(?,?,5,?)'
        cpuid_val = data.get('cpuid')
        actor_val = data.get('Actor')
        timestamp_val = data.get('timestamp')
        actor_addr_val = data.get('ActorAddr')
        if self.task_start_time is None or self.task_start_time.get(cpuid_val) is None:
            attr = cpuid_val
            self.task_start_time[attr] = timestamp_val
            self.task_end_time[attr] = timestamp_val
            self.task_name[attr] = actor_addr_val + ":" + actor_val
            self.cpup_start_time[attr] = float(timestamp_val)
            self.heap_start_time = float(timestamp_val)
            self.cpup_last_start_time[attr] = float(timestamp_val)

        # Event interface data writing
        sql_all.append({
            'sql': sqlInsert,
            'data': [
                timestamp_val,
                data.get('timestampOri'),
                cpuid_val,
                data.get('eventCount'),
                data.get('eventType'),
                data.get('identity'),
                json.dumps(data)
            ]
        })

        is_exists = 0
        for id_term in self.cpu_id:
            if id_term == cpuid_val:
                is_exists = 1
                break
        if is_exists == 0:
            self.cpu_id.append(cpuid_val)
            sql_all.append({
                'sql': sqlInsert_cpuid,
                'data': [
                    timestamp_val,
                    cpuid_val,
                    json.dumps(cpuid_val)
                ]
            })

    def set_time_line_data(self, data, sql_all):
        sqlInsert_timeline = 'insert into Timeline(timestamp, cpuid,datatype, itemstring) values(?,?,0,?)'
        cpuid_val = data.get('cpuid')
        actor_val = data.get('Actor')
        actor_addr_val = data.get('ActorAddr')
        timestamp_val = data.get('timestamp')
        addr_and_task = actor_addr_val + ':' + actor_val
        if actor_val != 'Interrupt':
            if self.last_task.get(cpuid_val) and addr_and_task != self.last_task.get(cpuid_val):
                # Task scheduling, Start time of the calculation task, Duration
                data_line = {
                        'timestamp': self.task_start_time.get(cpuid_val),
                        'starttime': self.task_start_time.get(cpuid_val),
                        'endtime': self.task_end_time.get(cpuid_val),
                        'taskname': self.last_task.get(cpuid_val).split(":")[1],
                        'cpuid': cpuid_val,
                        'type': self.task_type,
                        'ActorAddr': self.last_task.get(cpuid_val).split(":")[0]
                }
                # Writing Data on the Swimlane Diagram Interface,If the current task name changes,record the data once.
                sql_all.append({
                    'sql': sqlInsert_timeline,
                    'data': [
                        self.task_start_time.get(cpuid_val),
                        cpuid_val,
                        json.dumps(data_line)
                    ]
                })
                self.task_start_time[cpuid_val] = self.task_end_time.get(cpuid_val)
                self.last_task[cpuid_val] = addr_and_task
                self.last_time_line_sql[cpuid_val] = []
            elif self.last_task.get(cpuid_val) is None:
                self.last_task[cpuid_val] = addr_and_task

            data_line = {
                        'timestamp': self.task_start_time[cpuid_val],
                        'starttime': self.task_start_time[cpuid_val],
                        'endtime': timestamp_val,
                        'taskname': self.last_task.get(cpuid_val).split(":")[1],
                        'cpuid': cpuid_val,
                        'type': self.task_type,
                        'ActorAddr': self.last_task.get(cpuid_val).split(":")[0]
            }
            self.last_time_line_sql[cpuid_val] = [
                self.task_start_time[cpuid_val],
                cpuid_val,
                json.dumps(data_line)
            ]
        self.task_end_time[cpuid_val] = timestamp_val

    def set_cpu_usage_data(self, data, sql_all):
        sqlInsert_cpu = 'insert into CpuUsage(timestamp, cpuid,datatype, itemstring) values(?,?,2,?)'
        cpuid_val = data.get('cpuid')
        actor_val = data.get('Actor')
        actor_addr_val = data.get('ActorAddr')
        timestamp_val = data.get('timestamp')
        addr_and_task = actor_addr_val + ':' + actor_val

        # The CPU view data is written. If the interval is greater than 0.1s, the data is recorded once.
        # calculation interval cpu usage
        if actor_val != 'Interrupt':
            time_start = self.cpup_last_start_time.get(cpuid_val, '0')
            time_duration = float(timestamp_val) - float(time_start)
            if self.cpup_tasks.get(cpuid_val) is None:
                self.cpup_tasks[cpuid_val] = {}
            elif self.cpup_tasks.get(cpuid_val, {}).get(addr_and_task):
                self.cpup_tasks[cpuid_val][addr_and_task] += time_duration
            else:
                self.cpup_tasks[cpuid_val][addr_and_task] = time_duration

            if float(timestamp_val) - self.cpup_start_time.get(cpuid_val, 0) < CPU_INTERVAL:
                self.cpup_last_start_time[cpuid_val] = timestamp_val
            else:
                cpup_data = {}
                self.set_cpup_data(cpup_data, cpuid_val)

                # Save in the database
                cpup_data['count'] = self.cpup_count
                cpup_data['timestamp'] = timestamp_val
                sql_all.append({
                    'sql': sqlInsert_cpu,
                    'data': [
                        timestamp_val,
                        cpuid_val,
                        json.dumps(cpup_data)
                    ]
                })
                # Re-statistics
                self.cpup_tasks[cpuid_val] = {}
                self.cpup_count += 1
                self.cpup_start_time[cpuid_val] = float(timestamp_val)
                self.cpup_last_start_time[cpuid_val] = float(timestamp_val)

    def set_cpup_data(self, cpup_data, cpuid_val):
        sum_tasks = 0
        for t in self.cpup_tasks.get(cpuid_val):
            sum_tasks += self.cpup_tasks[cpuid_val][t]
            try:
                cpup_data[t] = round((self.cpup_tasks[cpuid_val][t] / sum_tasks) * 1000, 2)
            except ZeroDivisionError:
                cpup_data[t] = self.cpup_tasks[cpuid_val][t]

    def set_task_state(self, data):
        if data.get('code') == '0x' + str(hex(LOS_TRACE_TYPE.TRACE_EVENT_DELETE.value)):
            task_index = 0
            for idx, item in enumerate(self.task_datas):
                if item.get('taskId') == data.get('identity')[6: 10]:
                    task_index = idx
                    break
            self.task_datas[task_index]['state'] = 'delete'

    def set_heap_mem_data(self, data, sql_all):
        # Memory view data is written. If the interval is greater than 0.1s, the data is recorded once.
        # calculation heap
        sqlInsert_heap = 'insert into MemoryUsage(timestamp, datatype, pool, itemstring) values(?,3,?,?)'
        sqlInsert_memPool = 'insert into MemPool(timestamp, memPool,datatype, itemstring) values(?,?,6,?)'
        timestamp_val = data.get('timestamp')
        head_used_val = data.get('heapUsed')
        actor_val = data.get('Actor')
        actor_addr_val = data.get('ActorAddr') 
        if float(timestamp_val) - self.heap_start_time >= MEM_INTERVAL or head_used_val:
            heap_usage = head_used_val if head_used_val else '0'
            heap_usage_index = str(head_used_val).find('/')
            task_name = actor_addr_val + ':' + actor_val
            if heap_usage_index >= 0:
                heap_usage_used_val = head_used_val[0: heap_usage_index]
                heap_usage = heap_usage_used_val if heap_usage_used_val else '0'
                task_name = head_used_val[heap_usage_index + 1:]
            pool = data.get('identity') if head_used_val else ""
            if data.get('heapFree') or actor_val == 'Interrupt':
                task_name = '0xffffffff:System'
            heap_data = {
                'timestamp': timestamp_val,
                'pool': pool,
                'taskname': task_name,
                'heap_usage': heap_usage,
                'heap_free': data.get('heapFree')
            }

            sql_all.append({
                'sql': sqlInsert_heap,
                'data': [timestamp_val, heap_data.get('pool'), json.dumps(heap_data)]
            })
            self.heap_start_time = float(timestamp_val)
            if (heap_data.get('pool') and (heap_data.get('pool') not in self.mem_pool)):
                self.mem_pool[heap_data.get('pool')] = 1
                sql_all.append({
                    'sql': sqlInsert_memPool,
                    'data': [timestamp_val, heap_data.get('pool'), json.dumps(heap_data.get('pool'))]
                })

    def insert_trace_data_to_database(self, sql_insert, is_wait=True):
        if self.database is None:
            self.database = sqlite3.connect(self.database_path, timeout=1000, check_same_thread=False)
        if self.database is None:
            print('connect database failed')
            raise Exception()
        if self.database_cursor is None:
            self.database_cursor = self.database.cursor()
        self.sql_count += len(sql_insert)
        self.sql_data = self.sql_data + sql_insert
        # To improve database write performance and avoid frequent write, write every 60 records in online mode.
        is_sql_data_valid = len(self.sql_data) > 60 or self.trace_header.trace_mode == 0
        is_sql_count_valid = is_wait == False or self.sql_count < 1000
        if is_sql_data_valid or is_sql_count_valid:
            for sql_data_val in self.sql_data:
                self.database_cursor.execute(sql_data_val.get('sql'), sql_data_val.get('data'))
            self.database.commit()
            self.sql_data = []

    def init_trace_data(self):
        # Creating a temporary database
        ret = self.database_service.create_tmp_database()
        if not ret:
            print("Failed to start the trace, please confirm whether to open the local database")
            raise Exception()
        else:
            self.init(self.database_service.database_path)
            self.database_service.init()
            data = self.database_service.get_table_size(DataType.TraceLiteEvent.value)
            data_count = data.get("count")
            end_row = 0
            start_row = -10000
            sql = " order by timestamp asc"
            condition = dict(cond=sql, parames=[])
            indexCount = math.ceil(data_count / 10000)
            for _ in range(indexCount):
                start_row = start_row + 10000
                end_row = data_count if end_row + 10000 > data_count else end_row + 10000
                data = self.database_service.get_data_by_index(DataType.TraceLiteEvent.value, 
                                                               start_row, 
                                                               end_row, 
                                                               condition
                                                               )
                is_finished = True if end_row == data_count else False
                sql_all = self.insert_trace_event_data(data.get("items"), False, is_finished)
                self.database_service.insert_trace_data_to_database(sql_all)

            time.sleep(5)
            self.database_service.close_tmp_database()
            ret = self.database_service.save_data(self.database_service.database_path_tmp, 
                                                  self.database_service.database_path
                                                  )
